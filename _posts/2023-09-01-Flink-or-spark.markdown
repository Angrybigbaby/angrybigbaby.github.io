---
layout:     post
title:      "Flink还是Spark？"
subtitle:   "就说跑批，你选谁？"
date:       2023-09-01 
author:     "Bigbaby"
catalog:    true
tags:
    - Flink
    - Spark
---

> 如果面试官用耐人寻味的口气问出了这个问题，那么你可能要在降薪和放弃之间二选一了。这道表面上的开放题，实则是地地地道道的送命题

## Flink和Spark的前世今生

Spark 是一种快速、通用、可扩展的大数据分析引擎，2009 年诞生于加州大学伯克利分校AMPLab，2010年开源，2013年6月成为Apache孵化项目，2014年2月成为Apache顶级项目，用Scala进行编写项目框架。

从世界著名的开发者论坛Stack Overflow的数据可以看出，2015年开始Spark每月的问题提交数量已经超越Hadoop。Spark凭借高度兼容Hadoop生态，以及相比Mapreduce、Tez而言的卓越性能，目前在国内是各行各业离线场景下受众最广的计算引擎解决方案。

我们可以把大数据计算引擎笼统的分为四代：

    第一代： Hadoop 承载的 MapReduce
    
    第二代： 支持DAG框架的计算引擎
    
    第三代： 内置DAG的支持
    
    第四代： 大数据统一计算引擎

其中Spark是第三代的代表。而Flink代表了第四代引擎。

Flink将传统批处理定义为有界流，并开创性的提出了无界流的概念。作为一个框架和分布式处理引擎，Flink对无界和有界数据流进行有状态计算，旨在在所有常见的集群环境中运行，以内存速度和任何规模执行计算。

听上去Flink的思想更加先进，定位下一代计算引擎，难道意味着Flink可以全面碾压Spark？没错你猜对了，事情没有这么简单。

![image](https://github.com/user-attachments/assets/617170eb-4bf9-4bf9-8d19-7a89c1872d5f)

## 经验之谈

在实时场景，早在Flink应运而生的初期，市场就对Flink和Spark的流处理能力已有定论。这种差距本身来自于设计思想的代差，因为Spark Streaming的本质还是微批计算。而Flink无界流的概念，将每条数据视为独立个体，以状态计算的形式源源不断地工作。不论从理论还是实践中，在延迟和吞吐量方面，Flink > Spark Streaming毫无争议。

然而在离线场景下，事情发生了变化。我曾从多方了解到，Flink批处理模式下，在生产环境的表现要弱于Spark，尤其是日增GB及以上级别的大数据量场景。我的几位同事认为，Spark离线场景下好于Flink是毫无疑问的。

但是紧接着面对我的下一个问题，大家不约而同都选择了沉默。

“为什么？”

## 浅尝辄止的分析

从批处理角度来看，Spark的运行机制是根据宽依赖划分stage，由DAGScheduler结合并行度将DAG拉宽，形成具体的Task划分。

再由Taskscheduler将Task分配到具体的Executor上执行。

而Flink具有算子链优化机制，将算子的subtasks链接成task（减少了线程切换和缓存开销），每个task由一个线程执行。提交运行前依据程序代码构建StreamingDataFlow，通过将多个符合条件的节点chain在一起作为一个节点（Operator Chains），形成JobGraph。

将Job Graph加上Operator并行度，形成ExecutionGraph。申请资源，将Execution Graph执行图中SubTask运行在Slot 资源槽中，考虑槽共享，形成物理 Execution Graph。

所以从运行机制上看，两者的思想是相似的。
	
从底层的内存管理上看，Spark的内存管理由JVM托管，而Flink使用自主的内存管理避免了一些JVM内存管理的不足，如缓存未命中问题（Java对象在堆上存储的时候并不是连续的，所以从内存中读取Java对象时，缓存的邻近的内存区域的数据往往不是CPU下一步计算所需要的，这就是缓存未命中。此时CPU需要空转等待从内存中重新读取数据。）

Flink也会基于cpu L1 L2 L3高速缓存的机制以及局部性原理，设计使用缓存友好的数据结构。

Spark底层数据模型是弹性分布式数据集（RDD），Spark Streaming进行微批处理的底层接口DStream，实际上处理的也是一组组小批数据 RDD 的集合。可以看出，Spark在设计上本身就是以批量的数据集作为基准的，更加适合批处理的场景。

而Flink的基本数据模型是数据流（DataFlow），以及事件（Event）序列。Flink基本上是完全按照Google的DataFlow模型实现的，所以从底层数据模型上看，Flink是以处理流式数据作为设计目标的，更加适合流处理的场景。

数据模型不同，对应在运行处理的流程上，自然也会有不同的架构。Spark需要将任务对应的DAG划分阶段（Stage），一个完成后经过shuffle再进行下一阶段的计算。而Flink是标准的流式执行模式，一个事件在一个节点处理完后可以直接发往下一个节点进行处理。

## 如何选型

从理论上分析了二者的差异后，我们要面临实际选型问题。假设你作为公司技术团队的负责人，在这离线项目中会做何选择呢？

其实技术层面的理论分析只是选型决策过程中的一个因素。这个过程还要考虑到团队技术储备，项目整体架构，人员学习成本，社区活跃度，大厂应用背景，稳定性，兼容性，个人熟悉程度，客户/供应商倾向性等等因素。那么综合这些因素，应该如何取舍？

我会倾向于Spark，原因有三：

1. 在海量数据的离线场景中，Spark有一些不可替代的优点。比如Spark的RDD缓存（持久化）可以减少重复计算，对性能提升明显。而且CDH早期版本已经集成了Spark，安装成本更低。

2. Spark我很熟悉。过去几年我负责的离线项目，Spark基本上是标配。用Flink怕踩坑。

3. Hive on Spark真的很好用。相比而言，FlinkSQL Client需要配置catelog才能直接访问Hive元数据，且FlinkSQL方言有一定差异。这些差异增加了潜在的学习成本和解决问题的时间，不喜欢。

> 如今Flink已经即将迎来2.0时代，官方宣称其FlinkSQL计算能力在不断提升。那么是否意味着，离线场景Flink要超越Spark？我认为永远要结合场景来看。而且相比于相信官方的话术，自己亲自动手测试是最优解。因为没什么比事实更有说服力了。
